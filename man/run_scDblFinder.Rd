% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/run_scDblFinder.R
\name{run_scDblFinder}
\alias{run_scDblFinder}
\title{wrapper for running scDblFinder}
\usage{
run_scDblFinder(
  obj,
  knownDoublets = NULL,
  knownUse = NULL,
  nfeatures = 2000,
  ...
)
}
\arguments{
\item{obj}{A minimally processed seurat object}

\item{knownDoublets}{An optional logical vector of known doublets (e.g.
through cell barcodes), or the name of a colData column of `sce` containing
that information. The way these are used depends on the `knownUse` argument.}

\item{knownUse}{The way to use known doublets, either 'discard' (they are
discarded for the purpose of training, but counted as positive for 
thresholding) or 'positive' (they are used as positive doublets for training 
- usually leads to a mild decrease in accuracy due to the fact that known 
doublets typically include a sizeable fraction of homotypic doublets). Note
that `scDblFinder` does *not* enforce that the knownDoublets be necessarily
called as doublets in the final classification, if they are not predicted as 
such.}

\item{nfeatures}{The number of top features to use. Alternatively, a 
character vectors of feature names (e.g. highly-variable genes) to use.}

\item{...}{
  Arguments passed on to \code{\link[scDblFinder:scDblFinder]{scDblFinder::scDblFinder}}
  \describe{
    \item{\code{sce}}{A \code{\link[SummarizedExperiment]{SummarizedExperiment-class}},
\code{\link[SingleCellExperiment]{SingleCellExperiment-class}}, or array of
counts.}
    \item{\code{clusters}}{The optional cluster assignments. This is used to make
doublets more efficiently. \code{clusters} should either be a vector of
labels for each cell, or the name of a colData column of \code{sce}.
Alternatively, if `clusters=TRUE`, fast clustering will be performed. If
`clusters` is a single integer, it will determine how many clusters to
create (using k-means clustering). If `clusters` is NULL or FALSE, purely
random artificial doublets will be generated.}
    \item{\code{samples}}{A vector of the same length as cells (or the name of a column
of \code{colData(x)}), indicating to which sample each cell belongs. Here, a
sample is understood as being processed independently. If omitted, doublets
will be searched for with all cells together. If given, doublets will be
searched for independently for each sample, which is preferable if they
represent different captures. If your samples were multiplexed using cell
hashes, want you want to give here are the different batches/wells (i.e.
independent captures, since doublets cannot arise across them) rather
than biological samples.}
    \item{\code{clustCor}}{Include Spearman correlations to cell type averages in the
predictors. If `clustCor` is a matrix of cell type marker expressions (with
features as rows and cell types as columns), the subset of these which are
present in the selected features will be correlated to each cell to produce
additional predictors (i.e. one per cell type). Alternatively, if `clustCor`
is a positive integer, this number of inter-cluster markers will be selected
and used for correlation (se `clustCor=Inf` to use all available genes).}
    \item{\code{artificialDoublets}}{The approximate number of artificial doublets to
create. If \code{NULL}, will be the maximum of the number of cells or
\code{5*nbClusters^2} (with a minimum of 1500).}
    \item{\code{dbr}}{The expected doublet rate. By default this is assumed to be 1\%
per thousand cells captured (so 4\% among 4000 thousand cells), which is
appropriate for 10x datasets. Corrections for homeotypic doublets will be
performed on the given rate.}
    \item{\code{dbr.sd}}{The uncertainty range in the doublet rate, interpreted as
a +/- around `dbr`. During thresholding, deviation from the expected doublet
rate will be calculated from these boundaries, and will be considered null
within these boundaries. If NULL, will be 40\% of `dbr`. Set to `dbr.sd=0` to
 disable the uncertainty around the doublet rate, or to `dbr.sd=1` to disable
 any expectation of the number of doublets (thus letting the thresholding be
 entirely driven by the misclassification of artificial doublets).}
    \item{\code{dims}}{The number of dimensions used.}
    \item{\code{k}}{Number of nearest neighbors (for KNN graph). If more than one value
is given, the doublet density will be calculated at each k (and other values
at the highest k), and all the information will be used by the classifier.
If omitted, a reasonable set of values is used.}
    \item{\code{removeUnidentifiable}}{Logical; whether to remove artificial doublets of
a combination that is generally found to be unidentifiable.}
    \item{\code{includePCs}}{The index of principal components to include in the
predictors (e.g. `includePCs=1:2`), or the number of top components to use
(e.g. `includePCs=10`, equivalent to 1:10).}
    \item{\code{propRandom}}{The proportion of the artificial doublets which
should be made of random cells (as opposed to inter-cluster combinations).
If clusters is FALSE or NULL, this is ignored (and set to 1).}
    \item{\code{propMarkers}}{The proportion of features to select based on marker
identification.}
    \item{\code{aggregateFeatures}}{Whether to perform feature aggregation (recommended
for ATAC). Can also be a positive integer, in which case this will indicate
the number of components to use for feature aggregation (if TRUE, `dims`
will be used.)}
    \item{\code{returnType}}{Either "sce" (default), "table" (to return the table of
cell attributes including artificial doublets), or "full" (returns an SCE
object containing both the real and artificial cells).}
    \item{\code{score}}{Score to use for final classification.}
    \item{\code{processing}}{Counts (real and artificial) processing before KNN. Either
'default' (normal \code{scater}-based normalization and PCA), "rawPCA" (PCA
without normalization), "rawFeatures" (no normalization/dimensional
reduction), "normFeatures" (uses normalized features, without PCA) or a
custom function with (at least) arguments `e` (the matrix of counts) and
`dims` (the desired number of dimensions), returning a named matrix with
cells as rows and components as columns.}
    \item{\code{metric}}{Error metric to optimize during training (e.g. 'merror',
'logloss', 'auc', 'aucpr').}
    \item{\code{nrounds}}{Maximum rounds of boosting. If NULL, will be determined
through cross-validation. If a number <=1, will used the best
cross-validation round minus `nrounds` times the standard deviation of the
classification error.}
    \item{\code{max_depth}}{Maximum depths of each tree.}
    \item{\code{iter}}{A positive integer indicating the number of scoring iterations
(ignored if `score` isn't based on classifiers). At each iteration, real
cells that would be called as doublets are excluding from the training, and
new scores are calculated. Recommended values are 1 or 2.}
    \item{\code{trainingFeatures}}{The features to use for training (defaults to an
optimal pre-selection based on benchmark datasets). To exclude features
(rather than list those to be included), prefix them with a "-".}
    \item{\code{unident.th}}{The score threshold below which artificial doublets will be
considered unidentifiable.}
    \item{\code{multiSampleMode}}{Either "split" (recommended if there is
heterogeneity across samples), "singleModel", "singleModelSplitThres", or
"asOne" (see details below).}
    \item{\code{threshold}}{Logical; whether to threshold scores into binary doublet
calls}
    \item{\code{verbose}}{Logical; whether to print messages and the thresholding plot.}
    \item{\code{BPPARAM}}{Used for multithreading when splitting by samples (i.e. when
`samples!=NULL`); otherwise passed to eventual PCA and K/SNN calculations.}
  }}
}
\value{
A seurat object with additional metadata columns
}
\description{
Converts Seurat object to SCE for scDblFinder and returns
a seurat object with the scDblFinder outputs as added metadata.
}
\examples{
\dontrun{
  ## If you want to multithread, pass BPPARAM
  objs <- lapply(objs, run_scDblFinder, BPPARAM = BioCParallel::MulticoreParam(10, RNGseed = 45))
}
}
